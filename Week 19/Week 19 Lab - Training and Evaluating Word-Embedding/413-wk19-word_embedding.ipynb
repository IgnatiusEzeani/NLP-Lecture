{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 19: SCC.413 Applied Data Mining\n",
    "\n",
    "## Word Embedding Models - A Gentle Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "---\n",
    "* [1. Introduction](#intro)\n",
    "* [2. Training the Embedding Model](#embmodel)\n",
    "* [3. Querying word vectors: So, what does our trained model contain](#query)\n",
    "* [4. More querying: What can we do with the word vectors?](#morequery)\n",
    "* [5. Using Pretrained Embedding Models](#pretrained)\n",
    "* [6. Evaluating Pre-trained Word Embeddings](#evaluation)\n",
    "    * [6a. Task1: Vector Analogy](#analogy)\n",
    "        - [Exercise 1](#ex1)\n",
    "    * [6b. Task2: Sentiment Classification](#sentiments)\n",
    "        - [Exercise 2](#ex2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "## 1. Introduction\n",
    "---\n",
    "\n",
    "We have seen different (even more sophisticated) methods for preprocesing text in previous labs, so this merely a review. By now we have established that processing text and understanding the patterns there in is at the heart of whatever we do in data mining and NLP.\n",
    "\n",
    "Also, you may have noticed that machine learning algorithms we use to train our models for most of the downstream tasks prefer to have text inputs converted to some form of numerical data. When we perform classification of documents, for example, each document is an **input** and a class label is the **output** for our predictive algorithm. We give *vectors* of numbers (also called *input features*) as input.\n",
    "\n",
    "So, we need to convert documents to *fixed-length* vectors of numbers. *Scikit-learn*'s *CountVectorizer* is an example of a way to achieve that. In dealing with embedding models, we think beyond counting words but also capturing relationships between words.\n",
    "\n",
    "There are two key tasks in this lab:\n",
    "* **Answer analogy questions** with embedded vectors as described in [this paper](http://arxiv.org/pdf/1301.3781.pdf)\n",
    "    - e.g. `man` is to `king` what `man` is to `?`; (Answer = `queen`)\n",
    "\n",
    "* **Training a word sentiment classifier** as described in [this blog](http://blog.conceptnet.io/posts/2017/how-to-make-a-racist-ai-without-really-trying/)\n",
    "    - e.g. `awesome` is *positive* while `horrible` is *negative*\n",
    "    \n",
    "\n",
    "At the end of the lab, you will hopefully learn\n",
    "* how to training, save and load your own embedding models using the Gensim library (discussed later).\n",
    "* how to query trained word vectors\n",
    "    - similarity scores\n",
    "    - vector analogy\n",
    "    - odd-words\n",
    "    - Word Mover's Distance\n",
    "* how to fit a classfier with embbeding vectors as features\n",
    "\n",
    "\n",
    "Useful skills from previous labs:\n",
    "   \n",
    "   * file processing\n",
    "   * text processing\n",
    "   * training classifiers\n",
    "   * etc\n",
    "   \n",
    "Please remember to `pip install -r requirements.txt` to get the dependencies installed.\n",
    "\n",
    "---\n",
    "### Importing libraries ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# suppressing some deprecation warning..\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "The files for this exercise are kept in a folder named `data` with different subfolders, each of which will be used at different stages. We will normalise to lowercase and with each sentence in the list of sentences presented as a list of words. In creating our word embeddings, we will use the `CreateCorpus` class below to prepare our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "class CreateCorpus(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            for line in open(os.path.join(self.dirname, fname)):\n",
    "                yield line.lower().split()\n",
    "\n",
    "corpus = CreateCorpus('data/sentiment_data/all/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"embmodel\"></a>\n",
    "## 2. Training Embedding Model\n",
    "---\n",
    "The main purpose of this exercise is to see how to train a word embedding model. There are many ways to train embedding models. Some of the popular methods and libraries include:\n",
    "\n",
    " - Tomas Mikolov's [Word2vec](https://en.wikipedia.org/wiki/Word2vec),\n",
    " - Stanford University's [GloVe](https://nlp.stanford.edu/projects/glove/),\n",
    " - AllenNLP's [ELMo](https://allennlp.org/elmo),\n",
    " - FacebookAI's [fastText](https://en.wikipedia.org/wiki/FastText),\n",
    " - Radim Řehůřek's [Gensim](https://radimrehurek.com/gensim/index.html)\n",
    " - Google's [BERT](https://en.wikipedia.org/wiki/BERT_(language_model)) \n",
    " \n",
    "For our tasks, we shall use [Gensim](https://radimrehurek.com/gensim/index.html) which is an open source Python library for natural language processing, with a focus on [topic modeling](https://en.wikipedia.org/wiki/Topic_model). You can install Gensim with `pip install --upgrade gensim` (`pip install -r requirements.txt` installs all dependencies for this lab), if you haven't done so. I also find this [Gensim's tutorial and demo page](https://rare-technologies.com/word2vec-tutorial/) quite insightful too.\n",
    "\n",
    "---\n",
    "### Training Parameters\n",
    "Some of the common training parameters you may use to optimise your model based on your immediate task include:\n",
    "\n",
    " * **size:** (int, optional, default=100) – Dimensionality of the word vectors.\n",
    " * **window:** (int, optional, default=5) – Maximum distance between the current and predicted word within a sentence.\n",
    " * **min_count:** (int, optional, default=5) – Ignores all words with total frequency lower than this.\n",
    " * **workers:** (int, optional, default=3) – Use these many worker threads to train the model (=faster training with multicore machines).\n",
    " * **sg:** ({0, 1}, optional, default=0) – Training algorithm: 1 for *skip-gram(SG)*; otherwise *CBOW*.\n",
    " * **alpha:** (float, optional, default=0.025) – The initial learning rate.\n",
    " * **min_alpha:** (float, optional, default=0.0001) – Learning rate will linearly drop to min_alpha as training progresses.\n",
    " * **iter:** (int, optional, default=5) – Number of iterations (epochs) over the corpus.\n",
    " * **negative:** (int, optional, default=5) – If > 0, negative sampling will be used, the int for negative specifies how many “noise words” should be drawn (usually between 5-20). If set to 0, no negative sampling is used.\n",
    "\n",
    "See [this page](https://radimrehurek.com/gensim/models/word2vec.html) for other parameters if you wish to perform training optimisation later.\n",
    "\n",
    "---\n",
    "### Training our word embedding model\n",
    "So let's train a simple word embedding model that uses the parameters. The embedding dimension (size) 100.\n",
    "\n",
    "To train the model, we simply pass our list of `corpus` (*sentences*) to the Word2Vec object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_sentiment_model = Word2Vec(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done! That's it. We now have a model. We can look at some of the parameter configurations for training our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"query\"></a>\n",
    "## 3. Querying word vectors\n",
    "The *full model* often retains the training details allowing you to checkpoint it and continue training later with more data (more data implies better representation). But when the model is fully trained within certain bounds (e.g. domain, data size, embedding dimension, target task), we may only require the (pre-trained) word vectors as inputs to our downstream tasks. We will come back to that later.\n",
    "\n",
    "Some of the things we may be interested in with regards to text processing include:\n",
    "\n",
    " - **Model vocabulary** (may be different from the corpus vocabulary depending on pre-processing and model initial parameters)\n",
    " - **Frequency counts** (of words/tokens in model)\n",
    " - **Embedding dimension** (size)\n",
    "---\n",
    "### Model vocabulary\n",
    "We can use `twitter_sentiment_model.wv.vocab`to view the vocabulary built in training (`len(twitter_sentiment_model.wv.vocab)`). Looking at the list displayed below, you may decide, for example, what is okay to keep and what constitutes noise (e.g. *his...*, *|*, *-&gt* and *numbers* in general) and, more importantly, how to deal with them e.g. using a better tokeniser, setting the right **min_count** parameter value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab length\n",
    "len(twitter_sentiment_model.wv.vocab)\n",
    "\n",
    "# vocab words\n",
    "for w in twitter_sentiment_model.wv.vocab:\n",
    "    print(f\"{w}, \", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency counts\n",
    "\n",
    "This list will show that a lot of the input words to the model are punctuations and stopwords. Depending on what your main task is, you may decide to retain or remove them before the model training using simple processing techniques learnt in the previous labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_token_freq(model,topn):\n",
    "    for w, v in sorted(list(model.wv.vocab.items()), key=lambda x:x[1], reverse=True)[:topn]:\n",
    "        if topn<=20:\n",
    "            print(f\"{w:>10s} {v.count:5d}\")\n",
    "        else:\n",
    "            print(f\"{w}({v.count}), \", end=\"\")\n",
    "show_top_token_freq(twitter_sentiment_model, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding dimension\n",
    "So, it is basically a *vector* (a list of numbers) with length equal to the value assigned to the `size` parameter during train. Remember, we used `size = 100` in the training example above, but often most of the pre-trained models (such as [Glove](https://nlp.stanford.edu/projects/glove/), [Word2Vec](https://code.google.com/archive/p/word2vec/), [fastText](https://fasttext.cc/)) will use higher dimensions (50, 100, 200, 300) training on 100s of billions of tokens to capture better semantic information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_sentiment_model.wv.get_vector(\"the\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a model\n",
    "Again because we used a toy corpus for this training, we can afford to train and retrain so many times. In reality, you don't want to throw away your (hard) trained model because it takes a lot of time and is very computationally expensive to train a 'good enough' model.\n",
    "\n",
    "There are basically two ways you can save the model:\n",
    "\n",
    "* *full model*: `model.save('path\\to\\file_name')` contains the full model state (hidden weights, vocab frequencies and other training parameter values. You can initialise a new model with this and continue training at a later time.\n",
    "\n",
    "* *word vectors*: `model.save_word2vec_format('path\\to\\file_name')`. This is (more or less) the actual output of a training process. It is a plain text file with each line containing a token and its vector representation. Technically, you cannot continue training on this when loaded but you can  view it with a text editor (if not too large!) or process it as text file. Most pre-trained models are available in this format for re-use.\n",
    "\n",
    "For more options see [Usage examples on Gensim](https://radimrehurek.com/gensim/models/word2vec.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_sentiment_model.save('twitter_sentiment_model.bin')\n",
    "twitter_sentiment_model.wv.save_word2vec_format('twitter_sentiment_model.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"loading\"></a>\n",
    "### Loading a model\n",
    "You can load the *full model* or the *word vectors* for later use as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_bin = Word2Vec.load('twitter_sentiment_model.bin')\n",
    "loaded_model_txt = KeyedVectors.load_word2vec_format('twitter_sentiment_model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test loaded models\n",
    "loaded_model_bin['the']\n",
    "#loaded_model_txt['the']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"morequery\"></a>\n",
    "## 4. What we can do with word vectors\n",
    "\n",
    "Now we have seen how to configure, train, save and load embedding models. But what can we do with these pre-trained word vectors? Since word embedding models became popular in 2013 [Ruder,2018](https://ruder.io/tag/word-embeddings/) which also popularised the application of neural networks to NLP including:\n",
    "\n",
    "### Application areas\n",
    "\n",
    "    - Language modeling\n",
    "    - Information extraction\n",
    "    - Machine translation\n",
    "    - Named entity recognition\n",
    "    - Question answering\n",
    "    - Text classification\n",
    "    - etc.\n",
    "\n",
    "Also, here is an interesting blog on [why we use embedding models](https://towardsdatascience.com/why-do-we-use-embeddings-in-nlp-2f20e1b632d2).\n",
    "\n",
    "### How we can use word vectors\n",
    "\n",
    "A common way to use the embeddings to have it as a layer (the *embedding layer*) in a deep neural network setting i.e. the embedding is learned jointly with a neural network model on a specific natural language processing task. (That will not be our focus in this lab).\n",
    "\n",
    "But you can also use pre-trained vectors, combined in some format, as inputs to a classification algorithm. Obviously, your task determines how the vectors are created and/or combined and that can be optimised experimentally.\n",
    "\n",
    "In this lab we will be looking at a *very* simple sentiment classification task using pre trained vectors as inputs. Before that, let's look at some of the properties of a generic embedding model.\n",
    "\n",
    "---\n",
    "### Analogy - A Basic Question Answering problem \n",
    "\n",
    "#### `king` minus `man` plus `woman` = ?\n",
    "\n",
    "![](https://dpzbhybb2pdcj.cloudfront.net/smith4/Figures/f0207-01.jpg)\n",
    "\n",
    "One of the most popular tasks that word embedding supported (as demonstrated in this [Mikolov's paper](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)) was the *vector analogy* task. (You can read all about how and why it works [in this paper](https://levyomer.files.wordpress.com/2014/04/linguistic-regularities-in-sparse-and-explicit-word-representations-conll-2014.pdf). The key idea is that it can capture analogies like *man is to king* what *woman is to queen*. \n",
    "\n",
    "Therefore, if you get the vector for the word, say *king* and subtract the vector for *man* and then add the vector for *woman*, the closest approximation happens to be the vector for *queen* i.e. `vec(king) - vec(man) + vec(woman) ~= vec(queen)`\n",
    "\n",
    "We may not be able to see much with our toy dataset though, but let's explore a little\n",
    "\n",
    "---\n",
    "### Similarity measure\n",
    "From our model, let's look at the 10 most similar words (according to our model!) to each of these randomly selected words *man, woman, king, queen, good, bad, office, kitchen*. Here, we use *similarity* as measure of 'closeness' of words e.g. synonyms (*coast* vs *shore*) or related words (*clothes* and *closet*). This is a good paper in [similarity and relatedness](https://www.aclweb.org/anthology/D15-1242.pdf).\n",
    "\n",
    "What are the most similar words to *queen*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists(mdl, wd):\n",
    "    return mdl.__contains__(wd)\n",
    "\n",
    "def get_word_similarity(model, word, topn=10):\n",
    "    if exists(model, word):\n",
    "        vecs = [f\"{w}({v:.5f})\" for w, v in model.most_similar(word)]\n",
    "        print(f\"{word}:\\n{vecs}\")\n",
    "    else:\n",
    "        print(f\"'{word}' not found in this model\")\n",
    "    print(\"--\"*10)\n",
    "\n",
    "words = ['man', 'woman', 'king', 'queen', 'good', 'bad', 'office', 'kitchen']\n",
    "\n",
    "for word in words:\n",
    "     get_word_similarity(twitter_sentiment_model,word)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As *king* (or any word linked to royalty) is not seen in the most similar words to *queen*. It looks like our model may not be able to answer the question *king - man + woman $\\approx$ queen?* But let's try to find out. We don't even have `kitchen` in our vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = twitter_sentiment_model.wv.most_similar(positive=['woman', 'king'], negative=['man'])\n",
    "for word, score in result:\n",
    "    print(f\"{word:>15s}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, our model is struggling and this is not very surprising because it was trained with a comparative small amount of data data...too little to capture anything meaningful. It's common practice to use pre-trained models for your work unless you have a good reason not to (e.g. if they are too generic for your task) and you have a lot of time and compute resources. \n",
    "\n",
    "---\n",
    "<a id=\"pretrained\"></a>\n",
    "## 5. Using Pretrained Embedding Models\n",
    "Using pre-trained models is common but, in some cases, it may be better to train your own embedding. Here is a paper on [when-and-why-using-pretrained-embedding](https://www.aclweb.org/anthology/N18-2084.pdf). It is about machine translation but has general advice.\n",
    "\n",
    "Gensim `download` API can be used to get these `Word2Vec` models but they may be too heavy for the lab:\n",
    "\n",
    "    word2vec-google-news-300 (1662 MB) (dimensionality: 300)\n",
    "    word2vec-ruscorpora-300 (198 MB) (dimensionality: 300)\n",
    "\n",
    "Alternatively, there are lighter versions trained with the [GloVe](https://nlp.stanford.edu/projects/glove/) architecture described in [this paper](https://nlp.stanford.edu/pubs/glove.pdf). \n",
    "\n",
    "    glove-wiki-gigaword-50 (65 MB)\n",
    "    glove-wiki-gigaword-100 (128 MB)\n",
    "    glove-wiki-gigaword-200 (252 MB)\n",
    "    glove-wiki-gigaword-300 (376 MB)\n",
    "\n",
    "For our lab exercise, we will use one of the pre-trained models that can be downloaded using the Gensim's `downloader` API, `glove-wiki-gigaword-100`as shown below. Also, the `data/word_vectors/` contains other versions with different dimensions which you can load and use.\n",
    "\n",
    "Also you can use the trained vectors irrespective of how they are trained ([Word2Vec](https://nlp.stanford.edu/projects/glove/), [fastText](https://fasttext.cc/), [WordRank](https://www.groundai.com/project/wordrank-learning-word-embeddings-via-robust-ranking/4), VarEmbed etc). Here is [a nice blog](https://rare-technologies.com/wordrank-embedding-crowned-is-most-similar-to-king-not-word2vecs-canute/) on the comparison of different embedding models. As demonstrated [above](#loading), Gensim represents them as a standalone structure called `KeyedVectors`.\n",
    "\n",
    "Let us use the `gensim.downloader` API for loading the Glove model (it takes a while) and check the most similar words to each word in `words` with the `glove_vectors`. Try to answer the *king - man + woman $\\approx$ queen?* question again. Compare the results with those of the previous model.\n",
    "\n",
    "First, let'd download the embeddings and save the vectors it for the classification task later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download pre-trained embeddings from gensim-data\n",
    "glove_50 = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backup the vector format for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_50.save_word2vec_format('data/word_vectors/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words:\n",
    "     get_word_similarity(glove_50,word)\n",
    "result = glove_50.most_similar(positive=['king', 'woman'], negative=['man'], topn=10)\n",
    "for word, score in result:\n",
    "    print(f\"{word:>15s}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, `queen` tops the list and that's good. Also, we can see that the list is made up of words that are expected in the context (e.g. royalty, womanhood etc.)\n",
    "\n",
    "You can try a few more analogy examples:\n",
    "\n",
    "    - positive=['uk', 'russia'], negative=['london'] = ?\n",
    "    - positive=['father', 'mother'], negative=['son'] = ?\n",
    "\n",
    "or anything you like, make something up.\n",
    "\n",
    "---    \n",
    "### Odd-word: Another simple question anwering task\n",
    "\n",
    "Here, we give a set of words to our model and let it pick the odd one out. Are the results below as expected? Give examples that can break it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(glove_50.doesnt_match('breakfast cereal dinner lunch'.split())) #cereal?\n",
    "print(glove_50.doesnt_match('london savannah manchester glasgow'.split())) #savannah?\n",
    "print(glove_50.doesnt_match('bad nice horrible disgusting'.split())) #nice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar documents with WMD\n",
    "[Word Mover's Distance (WMD)](https://markroxor.github.io/gensim/static/notebooks/WMD_tutorial.html) is an interesting technique in building machine learning models for [document retrieval](https://en.wikipedia.org/wiki/Document_retrieval). We will use the example sentences from the tutorial. How close are these sentence pairs?\n",
    "\n",
    "* [**Warning:** `pyemd` could not run on my Windows machine. Skip cell if you have problems running this]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_obama = 'Obama speaks to the media in Illinois'.lower().split()\n",
    "sentence_president = 'The president greets the press in Chicago'.lower().split()\n",
    "sentence_orange = 'Oranges are my favorite fruit'.lower().split()\n",
    "\n",
    "similarity1 = glove_50.wmdistance(sentence_obama, sentence_president)\n",
    "similarity2 = glove_50.wmdistance(sentence_obama, sentence_orange)\n",
    "similarity3 = glove_50.wmdistance(sentence_orange, sentence_president)\n",
    "\n",
    "print(f\"{'[sentence_obama, sentence_president]':38s}: {similarity1:.4f}\")\n",
    "print(f\"{'[sentence_obama, sentence_orange]':38s}: {similarity2:.4f}\")\n",
    "print(f\"{'[sentence_orange, sentence_president]':38s}: {similarity3:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluating Pre-trained Word Embeddings\n",
    "<a id=\"evaluation\"></a>\n",
    "We have seen how pre-trained embeddings are loaded and queried and the interesting information they capture. But we need to be able to evaluate them i.e. to measure the probability of their usefulness in real world scenarios. Often these evaluations can be in two ways:\n",
    "\n",
    "* *intrinsic evaluation*  applies word-vectors to *specific intermediate subtasks* (e.g. *analogy completion*, *word similarity and relatedness*). These subtasks are simple and shows whether the model is behaving as expected, or not, and why.\n",
    "\n",
    "* *extrinsic evaluation* applies the vectors on a real world task, typically elaborate and slow to compute. Typically, optimizing an underperforming system in this case is hard and so we often use intrinsic evaluations during development.\n",
    "   \n",
    "See this lecture note on [Evaluation of Word Vectors](https://cs224d.stanford.edu/lecture_notes/notes2.pdf) and  [Evaluating Word Embedding Models: Methods and Experimental Results](https://arxiv.org/pdf/1901.09785.pdf) for details on evaluation methods.\n",
    "\n",
    "<a id=\"analogy\"></a>\n",
    "### 6a. Task1: Vector Analogy\n",
    "\n",
    "This task is described in *Section 4.1* of the paper [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781v3.pdf).\n",
    "\n",
    "<img src=\"questions-answers.png\" width=600>\n",
    "\n",
    "**Task Setup: **\n",
    "* *Aim:* To measure the impact of vector `size` on model quality or performance\n",
    "\n",
    "* *Problem:* To answer semantic and syntactic questions such as `athens:greece::oslo:?` (*norway*) or `walking:worked::swimming:?` (*swam*), `big:bigger::small:?` (*smaller*)\n",
    "\n",
    "* *Dataset:* In `data/analogy/questions-words.txt`. Categories: 5 semantic; 9 syntactic (see Table 1) 8869 semantic and 10675 syntactic questions. **[10% of each category's questions should be enough.]**\n",
    " \n",
    "* *Method:* `big:bigger::small:?`, compute `answer = vector(”biggest”) − vector(”big”) + vector(”small”)` with *cosine similarity* (use a library function). Correct if *most similar* ==  *smaller* otherwise wrong.\n",
    "\n",
    "---\n",
    "<a id=\"ex1\"></a>\n",
    "## Exercise 1: Vector Analogy (Not Assessed)\n",
    "* Compare the performance of the two models on the analogy task defined above:\n",
    "\n",
    "        glove_50 = api.load(\"glove-wiki-gigaword-50\")\n",
    "        glove_100 = api.load(\"glove-wiki-gigaword-100\")\n",
    "\n",
    "Show the:\n",
    "\n",
    "  - Overall performance on all questions (selected 10% from each category)\n",
    "  - Performance for each question type (i.e. semantic, syntactic)\n",
    "  - Performance for each category type (i.e. semantic, syntactic)\n",
    "\n",
    "* It's entirely up to you how you do this but you may need functions similar to these\n",
    "  - `getAnswer(question)` function\n",
    "  - `getScore(y_test, y_pred)` function\n",
    "  - `split_categories(questions)` or `split_types(questions)` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the file structure\n",
    "questions_words = open(\"data/analogy/questions-words.txt\", 'r', encoding='utf8').read().split(\"\\n\")\n",
    "questions_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Your solution here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sentiments\"></a>\n",
    "### 6b. Task2: Word Sentiment Classification\n",
    "\n",
    "In this exercise, we train a classifier that predicts the sentiment - *positive* or *negative* - of a given word using the sentiment lexicon on [Bing Liu's website](https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html#lexicon). It is actually a modified reproduction of the experiment presented [in this interesting blog](http://blog.conceptnet.io/posts/2017/how-to-make-a-racist-ai-without-really-trying/) about de-biasing embedding models. Following the same steps, we will: \n",
    "\n",
    "* Use our saved embeddings in `data/word_vectors/`\n",
    "* Get training and test data, with gold-standard examples of *positive* and *negative* words\n",
    "* Train a classifier to classify words as *positive* or *negative* given vector representations\n",
    "* Compute sentiment scores for texts with the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the word vectors models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a DataFrame from the generalized text format \n",
    "# Author: Robyn Speer\n",
    "def load_embeddings(filename):\n",
    "    rows, labels = [], []\n",
    "    with open(filename, encoding='utf-8') as infile:\n",
    "        for i, line in enumerate(infile):\n",
    "            items = line.rstrip().split(' ')\n",
    "            if len(items) == 2:\n",
    "                # This is a header row giving the shape of the matrix\n",
    "                continue\n",
    "            labels.append(items[0])\n",
    "            values = np.array([float(x) for x in items[1:]], 'f')\n",
    "            rows.append(values)\n",
    "    arr = np.vstack(rows)\n",
    "    return pd.DataFrame(arr, index=labels, dtype='f')\n",
    "\n",
    "glove_50 = load_embeddings('data/word_vectors/glove.6B.50d.txt')\n",
    "glove_50.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a sentiment lexicon\n",
    "\n",
    "In the Week 18, we used a gold-standard sentiment lexicon [(Hu and Liu, 2004)](https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html#lexicon) used for our work.\n",
    "\n",
    "In this lab, we will use it again to train a word sentiment classifier which uses only the embedding vectors as it's features. The cell below will load the positive and negative sentiment words into the variables `pos_words` and `neg_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a DataFrame from the generalized text format \n",
    "# Author: Robyn Speer\n",
    "def load_lexicon(filename):\n",
    "    lexicon = []\n",
    "    with open(filename, encoding='latin-1') as infile:\n",
    "        for line in infile:\n",
    "            line = line.rstrip()\n",
    "            if line and not line.startswith(';'):\n",
    "                lexicon.append(line)\n",
    "    return lexicon\n",
    "\n",
    "pos_words = load_lexicon('data/sentiment_lexicon/positive-words.txt')\n",
    "neg_words = load_lexicon('data/sentiment_lexicon/negative-words.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split\n",
    "Simultaneously separate the input vectors, output values, and labels into training and test data, with 10% of the data used for testing. Our classes are `positive` and `negative` words. Words that are not in the embedding e.g misspelt words (“fancinating”) are .dropna() to remove them. The rest are used for training.\n",
    "\n",
    "Here we will start with the `glove_50`, the inputs are the embeddings, and the outputs are `1` for *positive* words and `-1` for negative words. We keep track of the words they’re labeled with, so we can interpret the results. Your task will involve comparing our results here with the ones from using `glove_100`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_vectors = glove_50.reindex(pos_words).dropna()\n",
    "neg_vectors = glove_50.reindex(neg_words).dropna()\n",
    "\n",
    "vectors = pd.concat([pos_vectors, neg_vectors])\n",
    "targets = np.array([1 for entry in pos_vectors.index] + [-1 for entry in neg_vectors.index])\n",
    "\n",
    "labels = list(pos_vectors.index) + list(neg_vectors.index)\n",
    "\n",
    "train_vectors, test_vectors, train_targets, test_targets, train_labels, test_labels = \\\n",
    "    train_test_split(vectors, targets, labels, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluation\n",
    "We use the `SGDClassifier` setting only the `loss`, `random_state`, `n_iter` parameters. We use a logistic function as the loss, so that the resulting classifier can output the probability that a word is positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDClassifier(loss='log', random_state=0, max_iter=100)\n",
    "model.fit(train_vectors, train_targets)\n",
    "accuracy_score(model.predict(test_vectors), test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words and their sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vecs_to_sentiment(vecs):\n",
    "    # predict_log_proba gives the log probability for each class\n",
    "    predictions = model.predict_log_proba(vecs)\n",
    "\n",
    "    # To see an overall positive vs. negative classification in one number,\n",
    "    # we take the log probability of positive sentiment minus the log\n",
    "    # probability of negative sentiment.\n",
    "    return predictions[:, 1] - predictions[:, 0]\n",
    "\n",
    "def words_to_sentiment(words):\n",
    "    vecs = glove_50.reindex(words).dropna()\n",
    "    log_odds = vecs_to_sentiment(vecs)\n",
    "    return pd.DataFrame({'sentiment': log_odds}, index=vecs.index)\n",
    "\n",
    "# Show 20 examples from the test set\n",
    "words_to_sentiment(test_labels).iloc[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying texts\n",
    "We can pass the tokenised text (list of words) to the `words_to_sentiment` function as above and take the average of their returned predicted `predict_log_proba` scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_RE = re.compile(r\"\\w.*?\\b\")\n",
    "# The regex above finds tokens that start with a word-like character (\\w), and continues\n",
    "# matching characters (.+?) until the next word break (\\b). It's a relatively simple\n",
    "# expression that manages to extract something very much like words from text.\n",
    "\n",
    "def text_to_sentiment(text):\n",
    "    tokens = [token.lower() for token in TOKEN_RE.findall(text)]\n",
    "    sentiments = words_to_sentiment(tokens)\n",
    "    return sentiments['sentiment'].mean()\n",
    "\n",
    "s1 = text_to_sentiment(\"this example is pretty cool\")\n",
    "s2 = text_to_sentiment(\"food so tasteless dont go there\")\n",
    "s1,s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying tweets\n",
    "We can also do a similar thing with some positive and negative tweets an observe their returned scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = [\"\"\"Happy 50th Birthday Michelle Obama! \n",
    "                We're winding down our Friday with our \n",
    "                favorite FLOTUS quotes!\"\"\",\n",
    "       \"\"\"Jay Z 'pays tribute to Michael Jackson as he joins\n",
    "                Instagram' with touching photo, it may be his last\n",
    "                \"\"\"\n",
    "      ]\n",
    "\n",
    "neg = [\"\"\"California May Label Monsanto's Roundup as 'Known to Cause\n",
    "                Cancer' | Natural Society well it's about time!\"\"\", \n",
    "      \"\"\"Why in the name of Monsanto am I sitting @ home on Saturday\n",
    "         night trolling for used RVs on Craigslist..oh yeah,\n",
    "         I have no date\"\"\",\n",
    "      ] \n",
    "tweets = {\n",
    "    'pos': pos,\n",
    "    'neg': neg\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_sentiment_table():\n",
    "    sentiments={}\n",
    "    for sentiment, tweet_list in sorted(tweets.items()):\n",
    "        for i, tweet in enumerate(tweet_list):\n",
    "            sentiments.setdefault(sentiment,[]).append(text_to_sentiment(tweet.lower()))\n",
    "    return sentiments\n",
    "\n",
    "tweet_sentiments = tweet_sentiment_table()\n",
    "tweet_sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplot of tweet sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in tweet_sentiments:\n",
    "    plt.scatter([key]*2, tweet_sentiments[key], label=key)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"ex2\"></a>\n",
    "## Exercise 2: Sentiment classification (Not Assessed)\n",
    "\n",
    "* Using the embedded features in the two models in \"data/word_vectors\", and the sentiment lexicon used above, train a classifier for each model and present a comparative analysis of their analysis on\n",
    "    - word sentiment prediction\n",
    "    - tweet sentiment classfification using the positive and negative Twitter data in `data/sentiment_data`\n",
    "    \n",
    "* Train another classifer using the normal feature extraction methods used in the previous labs\n",
    "* Compare the results with the above and discuss your findings.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Your solution here..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
